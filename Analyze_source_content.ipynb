{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM3C6qqpwD7MgGKZ0szaiYW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Analyze source content\n",
        "Using standardized NLP functions and methods. Based on sota library (Langchain) and llm (Openai)."
      ],
      "metadata": {
        "id": "NrwIv2ZfFV6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load dependencies"
      ],
      "metadata": {
        "id": "_u3RIqxMFqF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "B8KbeLTDZvdx",
        "outputId": "470d1f47-b4bc-49c9-e908-24780b8d9e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Pillow\n",
            "  Using cached Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "Installing collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.5.0\n",
            "    Uninstalling Pillow-9.5.0:\n",
            "      Successfully uninstalled Pillow-9.5.0\n",
            "Successfully installed Pillow-9.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2Ap4KCcFUO5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6cf2cfb-b7c5-4808-c486-db158b06ed16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.188)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.7)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.3.25)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.5.3)\n",
            "Requirement already satisfied: hnswlib>=0.7 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.0)\n",
            "Requirement already satisfied: clickhouse-connect>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.5.25)\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.1)\n",
            "Requirement already satisfied: fastapi>=0.85.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.95.2)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.22.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.0.1)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.15.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.5.0)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.15)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7.1)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.85.1->chromadb) (0.27.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (3.6.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai tiktoken chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dependencies document loading Directoryloader needs Pillow 9.5.0\n",
        "!pip install unstructured[local-inference]\n",
        "!pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2\"\n",
        "!pip install layoutparser[layoutmodels,tesseract]\n",
        "!apt-get update\n",
        "!apt-get install -y libmagic-dev poppler-utils tesseract-ocr\n",
        "!pip install --ignore-installed Pillow==9.5.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u3ONrYLjYhHy",
        "outputId": "8c5a4151-1ed6-45b7-fad1-03f53311d0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unstructured[local-inference]\n",
            "  Downloading unstructured-0.7.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting argilla (from unstructured[local-inference])\n",
            "  Downloading argilla-1.8.0-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured[local-inference]) (4.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured[local-inference]) (4.9.2)\n",
            "Collecting msg-parser (from unstructured[local-inference])\n",
            "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured[local-inference]) (3.8.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured[local-inference]) (3.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unstructured[local-inference]) (1.5.3)\n",
            "Collecting pdfminer.six (from unstructured[local-inference])\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unstructured[local-inference]) (9.5.0)\n",
            "Collecting pypandoc (from unstructured[local-inference])\n",
            "  Downloading pypandoc-1.11-py3-none-any.whl (20 kB)\n",
            "Collecting python-docx (from unstructured[local-inference])\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-pptx (from unstructured[local-inference])\n",
            "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-magic (from unstructured[local-inference])\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured[local-inference]) (3.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured[local-inference]) (2.31.0)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured[local-inference]) (2.0.1)\n",
            "Collecting unstructured-inference==0.5.1 (from unstructured[local-inference])\n",
            "  Downloading unstructured_inference-0.5.1-py3-none-any.whl (39 kB)\n",
            "Collecting layoutparser[layoutmodels,tesseract] (from unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart (from unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub (from unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.5.1->unstructured[local-inference]) (4.7.0.72)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.5.1->unstructured[local-inference]) (1.15.0)\n",
            "Collecting transformers>=4.25.1 (from unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx<0.24,>=0.15 (from argilla->unstructured[local-inference])\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated~=1.2.0 (from argilla->unstructured[local-inference])\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured[local-inference]) (23.1)\n",
            "Requirement already satisfied: pydantic>=1.10.7 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured[local-inference]) (1.10.7)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.13 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured[local-inference]) (1.14.1)\n",
            "Requirement already satisfied: numpy<1.24.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured[local-inference]) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured[local-inference]) (4.65.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured[local-inference]) (2.2.1)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured[local-inference]) (1.6)\n",
            "Collecting rich<=13.0.1 (from argilla->unstructured[local-inference])\n",
            "  Downloading rich-13.0.1-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer<1.0.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured[local-inference]) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured[local-inference]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured[local-inference]) (2022.7.1)\n",
            "Collecting olefile>=0.46 (from msg-parser->unstructured[local-inference])\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[local-inference]) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[local-inference]) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[local-inference]) (2022.10.31)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured[local-inference]) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[local-inference]) (2.0.12)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[local-inference]) (40.0.2)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx->unstructured[local-inference])\n",
            "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[local-inference]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[local-inference]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[local-inference]) (2022.12.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[local-inference]) (1.15.1)\n",
            "Collecting httpcore<0.17.0,>=0.15.0 (from httpx<0.24,>=0.15->argilla->unstructured[local-inference])\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3 (from httpx<0.24,>=0.15->argilla->unstructured[local-inference])\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured[local-inference]) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.7->argilla->unstructured[local-inference]) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->unstructured[local-inference]) (1.16.0)\n",
            "Collecting commonmark<0.10.0,>=0.9.0 (from rich<=13.0.1->argilla->unstructured[local-inference])\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<=13.0.1->argilla->unstructured[local-inference]) (2.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.5.1->unstructured[local-inference]) (3.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.5.1->unstructured[local-inference]) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.5.1->unstructured[local-inference]) (0.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unstructured-inference==0.5.1->unstructured[local-inference]) (2023.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (1.10.1)\n",
            "Collecting iopath (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfplumber (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading pdfplumber-0.9.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdf2image (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (0.15.2+cu118)\n",
            "Collecting effdet (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytesseract (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime->unstructured-inference==0.5.1->unstructured[local-inference]) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->unstructured-inference==0.5.1->unstructured[local-inference]) (23.3.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime->unstructured-inference==0.5.1->unstructured[local-inference]) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime->unstructured-inference==0.5.1->unstructured[local-inference]) (1.11.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[local-inference]) (2.21)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured[local-inference]) (0.14.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured[local-inference]) (3.6.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime->unstructured-inference==0.5.1->unstructured[local-inference]) (10.0)\n",
            "Collecting timm>=0.9.2 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (2.0.6)\n",
            "Collecting omegaconf>=2.0 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (16.0.5)\n",
            "Collecting portalocker (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting Wand>=0.6.10 (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading Wand-0.6.11-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.6/143.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime->unstructured-inference==0.5.1->unstructured[local-inference]) (1.3.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (3.7.1)\n",
            "Collecting safetensors (from timm>=0.9.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (2.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (3.0.9)\n",
            "Building wheels for collected packages: python-docx, python-pptx, olefile, iopath, antlr4-python3-runtime\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184491 sha256=c87b19e663ab5c6d275f68e96798d03374e2b6617271d526cfb6757509275a7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470935 sha256=8bdf8106b3d5a9ce8d197a5388b1d93fd13a0f6ae79c307b54428fc1b20430d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/dd/74/01b3ec7256a0800b99384e9a0f7620e358afc3a51a59bf9b49\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=53f6f34bfdfc2ea51e75bcc7e174b91a6b601adc87845369b4082c4cdae23d10\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31531 sha256=9aada3053e9fb8fadcb0a9c67ab005ca681991446979319351c85fea850435bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=66ce03cdc2bbdf5e2deab5e57c091553e258641516f4d52ad9d9c7e259004a8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built python-docx python-pptx olefile iopath antlr4-python3-runtime\n",
            "Installing collected packages: Wand, safetensors, rfc3986, commonmark, antlr4-python3-runtime, XlsxWriter, rich, python-multipart, python-magic, python-docx, pytesseract, pypandoc, portalocker, pdf2image, omegaconf, olefile, deprecated, python-pptx, msg-parser, iopath, huggingface-hub, httpcore, transformers, pdfminer.six, httpx, pdfplumber, argilla, unstructured, layoutparser, timm, effdet, unstructured-inference\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.3.4\n",
            "    Uninstalling rich-13.3.4:\n",
            "      Successfully uninstalled rich-13.3.4\n",
            "Successfully installed Wand-0.6.11 XlsxWriter-3.1.2 antlr4-python3-runtime-4.9.3 argilla-1.8.0 commonmark-0.9.1 deprecated-1.2.14 effdet-0.4.1 httpcore-0.16.3 httpx-0.23.3 huggingface-hub-0.15.1 iopath-0.1.10 layoutparser-0.3.4 msg-parser-1.2.0 olefile-0.46 omegaconf-2.3.0 pdf2image-1.16.3 pdfminer.six-20221105 pdfplumber-0.9.0 portalocker-2.7.0 pypandoc-1.11 pytesseract-0.3.10 python-docx-0.8.11 python-magic-0.4.27 python-multipart-0.0.6 python-pptx-0.6.21 rfc3986-1.5.0 rich-13.0.1 safetensors-0.3.1 timm-0.9.2 transformers-4.29.2 unstructured-0.7.1 unstructured-inference-0.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git (to revision v0.6) to /tmp/pip-install-650ob2aj/detectron2_ae18362849824a9296d7851da9f2e80e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-install-650ob2aj/detectron2_ae18362849824a9296d7851da9f2e80e\n",
            "  Running command git checkout -q d1e04565d3bec8719335b88be9e9b961bf3ec464\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit d1e04565d3bec8719335b88be9e9b961bf3ec464\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (9.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.3.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.8.10)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (4.65.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.12.2)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.18.3)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.4.2)\n",
            "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.3.0)\n",
            "Collecting hydra-core>=1.1 (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black==21.4b2 (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2)\n",
            "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (8.1.3)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.4.4)\n",
            "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.10.2)\n",
            "Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2022.10.31)\n",
            "Collecting pathspec<1,>=0.8.1 (from black==21.4b2->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2)\n",
            "  Downloading pathspec-0.11.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (6.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (23.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.40.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (3.2.2)\n",
            "Building wheels for collected packages: detectron2, fvcore\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=7756222 sha256=deab2055f2fc3ca577dbd64e0d0b4c03d189e6774e36ed226caca57878f720ea\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vwcuk380/wheels/d0/62/a4/633b274d7706eff61ae574ae90fca694eeb99efbc2d719069f\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61405 sha256=c7b7b9fe93f987a20307951e35c0b2576752b1aa0630c07d6151021602f7b1b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "Successfully built detectron2 fvcore\n",
            "Installing collected packages: yacs, pathspec, iopath, hydra-core, fvcore, black, detectron2\n",
            "  Attempting uninstall: iopath\n",
            "    Found existing installation: iopath 0.1.10\n",
            "    Uninstalling iopath-0.1.10:\n",
            "      Successfully uninstalled iopath-0.1.10\n",
            "Successfully installed black-21.4b2 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 pathspec-0.11.1 yacs-0.1.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: layoutparser[layoutmodels,tesseract] in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]) (1.22.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]) (4.7.0.72)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]) (1.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]) (9.5.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]) (6.0)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]) (0.1.9)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]) (0.9.0)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]) (1.16.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]) (0.15.2+cu118)\n",
            "Requirement already satisfied: effdet in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]) (0.4.1)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]) (0.3.10)\n",
            "Requirement already satisfied: timm>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]) (0.9.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]) (2.0.6)\n",
            "Requirement already satisfied: omegaconf>=2.0 in /usr/local/lib/python3.10/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]) (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->layoutparser[layoutmodels,tesseract]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->layoutparser[layoutmodels,tesseract]) (16.0.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from iopath->layoutparser[layoutmodels,tesseract]) (4.65.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath->layoutparser[layoutmodels,tesseract]) (2.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser[layoutmodels,tesseract]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser[layoutmodels,tesseract]) (2022.7.1)\n",
            "Requirement already satisfied: pdfminer.six==20221105 in /usr/local/lib/python3.10/dist-packages (from pdfplumber->layoutparser[layoutmodels,tesseract]) (20221105)\n",
            "Requirement already satisfied: Wand>=0.6.10 in /usr/local/lib/python3.10/dist-packages (from pdfplumber->layoutparser[layoutmodels,tesseract]) (0.6.11)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber->layoutparser[layoutmodels,tesseract]) (2.0.12)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber->layoutparser[layoutmodels,tesseract]) (40.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract->layoutparser[layoutmodels,tesseract]) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->layoutparser[layoutmodels,tesseract]) (2.31.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]) (4.9.3)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]) (3.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->layoutparser[layoutmodels,tesseract]) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.2->effdet->layoutparser[layoutmodels,tesseract]) (0.15.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.2->effdet->layoutparser[layoutmodels,tesseract]) (0.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->layoutparser[layoutmodels,tesseract]) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->layoutparser[layoutmodels,tesseract]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->layoutparser[layoutmodels,tesseract]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->layoutparser[layoutmodels,tesseract]) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->layoutparser[layoutmodels,tesseract]) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber->layoutparser[layoutmodels,tesseract]) (1.15.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]) (3.0.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm>=0.9.2->effdet->layoutparser[layoutmodels,tesseract]) (2023.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber->layoutparser[layoutmodels,tesseract]) (2.21)\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:12 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,584 kB]\n",
            "Get:13 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,219 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,252 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,351 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1,011 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,056 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,773 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,345 kB]\n",
            "Fetched 15.9 MB in 2s (6,606 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  libmagic-dev poppler-utils tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 5 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 5,112 kB of archives.\n",
            "After this operation, 17.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libmagic-dev amd64 1:5.38-4 [88.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 poppler-utils amd64 0.86.1-0ubuntu1.1 [174 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1 [1,598 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1 [2,990 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr amd64 4.1.1-2build2 [262 kB]\n",
            "Fetched 5,112 kB in 1s (4,970 kB/s)\n",
            "Selecting previously unselected package libmagic-dev:amd64.\n",
            "(Reading database ... 122542 files and directories currently installed.)\n",
            "Preparing to unpack .../libmagic-dev_1%3a5.38-4_amd64.deb ...\n",
            "Unpacking libmagic-dev:amd64 (1:5.38-4) ...\n",
            "Selecting previously unselected package poppler-utils.\n",
            "Preparing to unpack .../poppler-utils_0.86.1-0ubuntu1.1_amd64.deb ...\n",
            "Unpacking poppler-utils (0.86.1-0ubuntu1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2build2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2build2) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up libmagic-dev:amd64 (1:5.38-4) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up poppler-utils (0.86.1-0ubuntu1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2build2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Pillow==9.5.0\n",
            "  Using cached Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\n",
            "Installing collected packages: Pillow\n",
            "Successfully installed Pillow-9.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Make the display a bit wider\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
        "\n",
        "# To split our transcript into pieces and search the content effectively\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# Our chat model and other functionality to chat with documents, default model is gpt-3.5-turbo\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.chains import (\n",
        "    RetrievalQA,\n",
        "    RetrievalQAWithSourcesChain\n",
        ")\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "\n",
        "# Prompt templates for dynamic values\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate\n",
        ")\n",
        "\n",
        "# To create our chat messages\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ],
      "metadata": {
        "id": "6dh72j59Ftg2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2c1e45a2-eea6-47a2-b09c-1b45b6e8edca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:90% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load credentials"
      ],
      "metadata": {
        "id": "eT5mdCck4WFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "1lYwNLGT4U3l",
        "outputId": "e14f5968-8189-49a5-fc84-07397d7c83fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cd25d7fc-b2af-4668-a21f-8d89f3fbb924\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cd25d7fc-b2af-4668-a21f-8d89f3fbb924\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving credentials.json to credentials (1).json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the credentials file\n",
        "import os\n",
        "import json\n",
        "with open('credentials.json', 'r', encoding = 'utf-8') as f:\n",
        "    credentials = json.load(f)\n",
        "os.environ['OPENAI_API_KEY'] = credentials['openai_api_key']\n",
        "openai_api_key = credentials['openai_api_key']"
      ],
      "metadata": {
        "id": "ZjVxzYTP4TxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup printing"
      ],
      "metadata": {
        "id": "XtiihnwvS550"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for printing output to console and files\n",
        "#You can call this function at the start of the NLP functions using logger = setup_logging('file_name')\n",
        "\n",
        "import logging\n",
        "\n",
        "def setup_logging(function_name):\n",
        "    # Set up logging\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    # If logger already has handlers, clear them\n",
        "    if logger.hasHandlers():\n",
        "        logger.handlers.clear()\n",
        "\n",
        "    # Create handlers\n",
        "    c_handler = logging.StreamHandler()\n",
        "    f_handler = logging.FileHandler(f'{function_name}_log.txt')\n",
        "    c_handler.setLevel(logging.INFO)\n",
        "    f_handler.setLevel(logging.INFO)\n",
        "\n",
        "    # Create formatters and add it to handlers\n",
        "    format = logging.Formatter('%(message)s')\n",
        "    c_handler.setFormatter(format)\n",
        "    f_handler.setFormatter(format)\n",
        "\n",
        "    # Add handlers to the logger\n",
        "    logger.addHandler(c_handler)\n",
        "    logger.addHandler(f_handler)\n",
        "\n",
        "    return logger"
      ],
      "metadata": {
        "id": "QoAz_vLNFt1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load and preprocess data"
      ],
      "metadata": {
        "id": "Wwb35tdw5KpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDzLoRnSXx3T",
        "outputId": "65e18bd9-5274-46ed-e0bb-4cc4bc7dbf38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load content to vectorstore and setup retriever\n",
        "gdrive_path = \"/content/drive/MyDrive/Data/q_a/moduchain/\"\n",
        "loader = DirectoryLoader(gdrive_path, glob='**/*')\n",
        "raw_documents = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=250)\n",
        "texts = text_splitter.split_documents(raw_documents)"
      ],
      "metadata": {
        "id": "e5s37atR5eap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorstoreIndexCreator().from_documents(texts)\n",
        "#index.save_to_disk(\"knowledgebase.json\") 'VectorStoreIndexWrapper' object has no attribute 'save_to_disk'\n",
        "vector_store = index.vectorstore\n",
        "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})"
      ],
      "metadata": {
        "id": "_bff3l1Cd1bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqB5xks8TtaI",
        "outputId": "66026a3a-7305-40ed-ca77-c48be156167d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7f2aac847190>, search_type='similarity', search_kwargs={'k': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preview\n",
        "print (f'You have {len(raw_documents)} document(s) in your directory')\n",
        "print (f'There are {len(raw_documents[0].page_content)} characters in your documents')\n",
        "print (f'After splitting you have {len(texts)} documents')\n",
        "print (\"Preview:\")\n",
        "print (texts[0].page_content, \"\\n\")\n",
        "print (texts[1].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mpjcWtSXLYt",
        "outputId": "512f69ca-34c4-4ec0-98aa-bad44d4e8acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have 2 document(s) in your directory\n",
            "There are 0 characters in your documents\n",
            "After splitting you have 32 documents\n",
            "Preview:\n",
            "Alles wat jullie zeggen is nieuw voor mij, laat ik het zo zeggen. Misschien kunnen we even beginnen met, want ongetwijfeld, Novolo kennen jullie al een beetje natuurlijk, maar misschien kunnen jullie iets over jullie bedrijf en over julliezelf vertellen? Ja, zal ik even persoonlijk introduceren? We hebben ook een aantal slides die we ook gebruiken als we bij klanten of potentiële klanten zijn. Dus ik denk dat die wel een beetje gaan helpen ook voor jou met content. Persoonlijk, ik ben dus Pepiche, ik ben 32 jaar, ik woon in Breda en heb een dochtertje van 2,5. Ja, zeker leuk, absoluut. Ik ben oorspronkelijk opgeleid in hotelmanagement. Vanuit daar wist ik eigenlijk al vrij snel dat ik niet de hotellerie in ging. Ik had het vrij internationaal georiënteerd geweest. Na de hbo-studie ervoor gekozen om een tussenjaar te doen bij een logistieke dienstverlener in de Sales. En vanuit daar gekozen voor een masterstudie organisatie wetenschappen in Tilburg. En daar is eigenlijk mijn carrière \n",
            "\n",
            "georiënteerd geweest. Na de hbo-studie ervoor gekozen om een tussenjaar te doen bij een logistieke dienstverlener in de Sales. En vanuit daar gekozen voor een masterstudie organisatie wetenschappen in Tilburg. En daar is eigenlijk mijn carrière begonnen en steeds meer in het consultatievak beland. Initieel bij een beetje de semi-overheid, Techniek Nederland onder andere. Maar dat ging me eigenlijk niet snel genoeg. Ik zocht naar meer innovatie en meer drive en energie. Toen ben ik bij Capgemini terecht gekomen. Daar ben ik als businessanalyst aan de slag gegaan. Daar kennen Richard en ik elkaar ook eens van. We hebben ook samen gewerkt in opdrachten bij Philips. We hebben samen een jaar aan een assignment gewerkt. En vanuit daar kwam eigenlijk altijd al ons ondernemerschap naar voren. We hadden het al bezig met proposities rondom supply chain. Want dat is onze invalshoek. En die komt nu dan een paar jaar later via Modichain. Maar als consultant, het snijvlak tussen business en IT is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NLP functions"
      ],
      "metadata": {
        "id": "s-4boqmaFuoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Search input documents only"
      ],
      "metadata": {
        "id": "zy6ln6pfF_pW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Search on bare docs itself (availability of vectorstore presumed)\n",
        "def ask_questions(vectordb, questions):\n",
        "    logger = setup_logging('ask_questions')\n",
        "    retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
        "    answers = []\n",
        "    for question in questions:\n",
        "        relevant_documents = retriever.get_relevant_documents(question)\n",
        "        answers.append(f\"Question: {question}\\n\")\n",
        "        answers.append(\"Relevant Documents:\\n\")\n",
        "        answers.extend(f\"{i + 1}. {doc.page_content}\\n\" for i, doc in enumerate(relevant_documents))\n",
        "        answers.append(\"=\" * 40 + \"\\n\\n\\n\")\n",
        "    for answer in answers:\n",
        "        logger.info(answer)\n",
        "    return ''.join(answers)"
      ],
      "metadata": {
        "id": "WcCG05o6GIJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling function\n",
        "questions = [\n",
        "    \"Waarom gaan Moduchain en Novulo een partnership aan?\",\n",
        "    \"Kun je uitleggen hoe het partnership implementaties en development beslaat?\",\n",
        "    \"Wat voor innovaties zullen er in het warehouse komen?\",\n",
        "    \"Wat is citizen development en wat kun je ermee bereiken vindt Moduchain?\",\n",
        "    \"Waarom is application composition platform van Novulo te mooi om waar te zijn?\",\n",
        "    # add more questions here\n",
        "]\n",
        "\n",
        "# Call the function\n",
        "answers = ask_questions(retriever, questions)\n",
        "\n",
        "# If you want to print the returned answers string\n",
        "print(answers)"
      ],
      "metadata": {
        "id": "poIFtAixKhHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b947b16a-7eca-428a-a129-90e809ebe601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Question: Waarom gaan Moduchain en Novulo een partnership aan?\n",
            "\n",
            "INFO:__main__:Question: Waarom gaan Moduchain en Novulo een partnership aan?\n",
            "\n",
            "Relevant Documents:\n",
            "\n",
            "INFO:__main__:Relevant Documents:\n",
            "\n",
            "1. De komende tijd de combinatie Novolo voor de logistiek. Dus als ik daar het taal naar de componenten zijn dat WMS componenten. Ja, in eerste instantie. Dus we hebben hier een inleiding voor. Ik denk wat belangrijk is waar wij voor staan. En waarom we zo'n goede match hebben met Novolo. Modulair supply chain. Wij staan voor modulairiteit. Dus gebruik wat je nodig hebt. En ook niet teveel, niet een overkeel. Maar je wil ook weer hebben wat je nodig hebt. En plug and play. Wat je ook wel veel ziet bij innovaties in de markt. Dat je heel veel tijd kwijt bent aan integratie ervan. Wij willen steeds meer naar plug and play. Dus makkelijker nieuwe functionaliteiten toevoegen. Daar sluit Novolo natuurlijk perfect op aan. Het moet innovatief zijn. Of innovaties kunnen faciliteren. En wat wij heel erg extra doen is menselijk aanpak. Ja, wat we in de afgelopen jaren wel vaak hebben gezien. Is dat als er een technische implementatie is. Waarbij het management, laat ik het even chargeren, gekozen\n",
            "\n",
            "INFO:__main__:1. De komende tijd de combinatie Novolo voor de logistiek. Dus als ik daar het taal naar de componenten zijn dat WMS componenten. Ja, in eerste instantie. Dus we hebben hier een inleiding voor. Ik denk wat belangrijk is waar wij voor staan. En waarom we zo'n goede match hebben met Novolo. Modulair supply chain. Wij staan voor modulairiteit. Dus gebruik wat je nodig hebt. En ook niet teveel, niet een overkeel. Maar je wil ook weer hebben wat je nodig hebt. En plug and play. Wat je ook wel veel ziet bij innovaties in de markt. Dat je heel veel tijd kwijt bent aan integratie ervan. Wij willen steeds meer naar plug and play. Dus makkelijker nieuwe functionaliteiten toevoegen. Daar sluit Novolo natuurlijk perfect op aan. Het moet innovatief zijn. Of innovaties kunnen faciliteren. En wat wij heel erg extra doen is menselijk aanpak. Ja, wat we in de afgelopen jaren wel vaak hebben gezien. Is dat als er een technische implementatie is. Waarbij het management, laat ik het even chargeren, gekozen\n",
            "\n",
            "========================================\n",
            "\n",
            "\n",
            "\n",
            "INFO:__main__:========================================\n",
            "\n",
            "\n",
            "\n",
            "Question: Kun je uitleggen hoe het partnership implementaties en development beslaat?\n",
            "\n",
            "INFO:__main__:Question: Kun je uitleggen hoe het partnership implementaties en development beslaat?\n",
            "\n",
            "Relevant Documents:\n",
            "\n",
            "INFO:__main__:Relevant Documents:\n",
            "\n",
            "1. Of innovaties kunnen faciliteren. En wat wij heel erg extra doen is menselijk aanpak. Ja, wat we in de afgelopen jaren wel vaak hebben gezien. Is dat als er een technische implementatie is. Waarbij het management, laat ik het even chargeren, gekozen heeft voor een bepaald pakket. En dat wordt zeg maar op de werkvloer gegooid. Dan is de draagvlakvraag niet heel. En zijn de resultaten dus ook niet heel. En dus zijn wij in ons implementatie model gaat de mens en technologie samen. En is het heel belangrijk om de draagvlak juist goed te organiseren. Zodat je ook echt profiteert van hetgeen wat je wil gaan doen. En even kijken, zijn jullie een solution provider of een consultancy club? Beide. Dus we hebben een solution. Als ik het vertaal naar NoFlow doen we een implementatie trajecten. Maar we willen ook componenten gaan ontwikkelen. En dan voornamelijk op het WMS stuk. In de groep WMS functionaliteiten en TMS functionaliteiten en OMS functionaliteiten. Dus eigenlijk alles wat supply\n",
            "\n",
            "INFO:__main__:1. Of innovaties kunnen faciliteren. En wat wij heel erg extra doen is menselijk aanpak. Ja, wat we in de afgelopen jaren wel vaak hebben gezien. Is dat als er een technische implementatie is. Waarbij het management, laat ik het even chargeren, gekozen heeft voor een bepaald pakket. En dat wordt zeg maar op de werkvloer gegooid. Dan is de draagvlakvraag niet heel. En zijn de resultaten dus ook niet heel. En dus zijn wij in ons implementatie model gaat de mens en technologie samen. En is het heel belangrijk om de draagvlak juist goed te organiseren. Zodat je ook echt profiteert van hetgeen wat je wil gaan doen. En even kijken, zijn jullie een solution provider of een consultancy club? Beide. Dus we hebben een solution. Als ik het vertaal naar NoFlow doen we een implementatie trajecten. Maar we willen ook componenten gaan ontwikkelen. En dan voornamelijk op het WMS stuk. In de groep WMS functionaliteiten en TMS functionaliteiten en OMS functionaliteiten. Dus eigenlijk alles wat supply\n",
            "\n",
            "========================================\n",
            "\n",
            "\n",
            "\n",
            "INFO:__main__:========================================\n",
            "\n",
            "\n",
            "\n",
            "Question: Wat voor innovaties zullen er in het warehouse komen?\n",
            "\n",
            "INFO:__main__:Question: Wat voor innovaties zullen er in het warehouse komen?\n",
            "\n",
            "Relevant Documents:\n",
            "\n",
            "INFO:__main__:Relevant Documents:\n",
            "\n",
            "1. De komende tijd de combinatie Novolo voor de logistiek. Dus als ik daar het taal naar de componenten zijn dat WMS componenten. Ja, in eerste instantie. Dus we hebben hier een inleiding voor. Ik denk wat belangrijk is waar wij voor staan. En waarom we zo'n goede match hebben met Novolo. Modulair supply chain. Wij staan voor modulairiteit. Dus gebruik wat je nodig hebt. En ook niet teveel, niet een overkeel. Maar je wil ook weer hebben wat je nodig hebt. En plug and play. Wat je ook wel veel ziet bij innovaties in de markt. Dat je heel veel tijd kwijt bent aan integratie ervan. Wij willen steeds meer naar plug and play. Dus makkelijker nieuwe functionaliteiten toevoegen. Daar sluit Novolo natuurlijk perfect op aan. Het moet innovatief zijn. Of innovaties kunnen faciliteren. En wat wij heel erg extra doen is menselijk aanpak. Ja, wat we in de afgelopen jaren wel vaak hebben gezien. Is dat als er een technische implementatie is. Waarbij het management, laat ik het even chargeren, gekozen\n",
            "\n",
            "INFO:__main__:1. De komende tijd de combinatie Novolo voor de logistiek. Dus als ik daar het taal naar de componenten zijn dat WMS componenten. Ja, in eerste instantie. Dus we hebben hier een inleiding voor. Ik denk wat belangrijk is waar wij voor staan. En waarom we zo'n goede match hebben met Novolo. Modulair supply chain. Wij staan voor modulairiteit. Dus gebruik wat je nodig hebt. En ook niet teveel, niet een overkeel. Maar je wil ook weer hebben wat je nodig hebt. En plug and play. Wat je ook wel veel ziet bij innovaties in de markt. Dat je heel veel tijd kwijt bent aan integratie ervan. Wij willen steeds meer naar plug and play. Dus makkelijker nieuwe functionaliteiten toevoegen. Daar sluit Novolo natuurlijk perfect op aan. Het moet innovatief zijn. Of innovaties kunnen faciliteren. En wat wij heel erg extra doen is menselijk aanpak. Ja, wat we in de afgelopen jaren wel vaak hebben gezien. Is dat als er een technische implementatie is. Waarbij het management, laat ik het even chargeren, gekozen\n",
            "\n",
            "========================================\n",
            "\n",
            "\n",
            "\n",
            "INFO:__main__:========================================\n",
            "\n",
            "\n",
            "\n",
            "Question: Wat is citizen development en wat kun je ermee bereiken vindt Moduchain?\n",
            "\n",
            "INFO:__main__:Question: Wat is citizen development en wat kun je ermee bereiken vindt Moduchain?\n",
            "\n",
            "Relevant Documents:\n",
            "\n",
            "INFO:__main__:Relevant Documents:\n",
            "\n",
            "1. altijd al ons ondernemerschap naar voren. We hadden het al bezig met proposities rondom supply chain. Want dat is onze invalshoek. En die komt nu dan een paar jaar later via Modichain. Maar als consultant, het snijvlak tussen business en IT is echt hetgeen wat wij begrijpen. Dat ligt in onze expertise. En we hebben verschillende industrieën en organisaties gezien. Dus wat ik eerder zei, bij Philips in de healthcare tak gezeten. Bij Rituals als omnichannel businessanalyst gewerkt. Bij Amgen in de gezondheidszorg. Dus meer patiënt gerelateerde zorgpaden. Maar de rode draad blijft eigenlijk altijd hetzelfde. Dat is namelijk het begrijpen van de businessbehoeften. En begrijpen hoe IT daar een ondersteunende rol in kan vinden. En er dan ook voor zorgen dat dat gerealiseerd wordt. Oké. Even kijken, mijn achtergrond is combinatie van communicatie en technologie. Ik heb onder andere bij Chipsoft gewerkt. Dus in de medische sector als projectmanager. Maar ook een tijd lang in de media gewerkt.\n",
            "\n",
            "INFO:__main__:1. altijd al ons ondernemerschap naar voren. We hadden het al bezig met proposities rondom supply chain. Want dat is onze invalshoek. En die komt nu dan een paar jaar later via Modichain. Maar als consultant, het snijvlak tussen business en IT is echt hetgeen wat wij begrijpen. Dat ligt in onze expertise. En we hebben verschillende industrieën en organisaties gezien. Dus wat ik eerder zei, bij Philips in de healthcare tak gezeten. Bij Rituals als omnichannel businessanalyst gewerkt. Bij Amgen in de gezondheidszorg. Dus meer patiënt gerelateerde zorgpaden. Maar de rode draad blijft eigenlijk altijd hetzelfde. Dat is namelijk het begrijpen van de businessbehoeften. En begrijpen hoe IT daar een ondersteunende rol in kan vinden. En er dan ook voor zorgen dat dat gerealiseerd wordt. Oké. Even kijken, mijn achtergrond is combinatie van communicatie en technologie. Ik heb onder andere bij Chipsoft gewerkt. Dus in de medische sector als projectmanager. Maar ook een tijd lang in de media gewerkt.\n",
            "\n",
            "========================================\n",
            "\n",
            "\n",
            "\n",
            "INFO:__main__:========================================\n",
            "\n",
            "\n",
            "\n",
            "Question: Waarom is application composition platform van Novulo te mooi om waar te zijn?\n",
            "\n",
            "INFO:__main__:Question: Waarom is application composition platform van Novulo te mooi om waar te zijn?\n",
            "\n",
            "Relevant Documents:\n",
            "\n",
            "INFO:__main__:Relevant Documents:\n",
            "\n",
            "1. nieuw. Ja precies. Frank heeft die term bij ons geïntroduceerd. Ja, dit is ook pas. Het is nog geen jaar dat Gartner er heel stevig mee komt. Ze hebben het bij model IT in gereild voor application composition. Om bedrijven aan het innoveren en te krijgen. En verbindbaar te maken. Ja. We hadden wel sterk het gevoel in het begin toen we hier mee in aanraking kwamen. Dat het een beetje zo'n to good to be true verhaal is. Ondertussen geloven wij er daadwerkelijk in dat het gewoon kan. Maar je merkt dat dat ook nog iets is wat we leveren. Dat het ook een beetje een to good to be true verhaal is. En dat het ook een beetje een to good to be true verhaal is. En dat het ook een beetje een to good to be true verhaal is. Dat is ook nog iets wat wel leeft bij sales gesprekken. Dan geven we vast een kleine cliffhanger. Het lijkt een to good to be true. Maar het kan echt. Oké. Ik heb het gevoel dat NoFlow zelf niet eens beseft. Op het gebied van WMS bijvoorbeeld. Hoe ver ze zijn. Want afgelopen\n",
            "\n",
            "INFO:__main__:1. nieuw. Ja precies. Frank heeft die term bij ons geïntroduceerd. Ja, dit is ook pas. Het is nog geen jaar dat Gartner er heel stevig mee komt. Ze hebben het bij model IT in gereild voor application composition. Om bedrijven aan het innoveren en te krijgen. En verbindbaar te maken. Ja. We hadden wel sterk het gevoel in het begin toen we hier mee in aanraking kwamen. Dat het een beetje zo'n to good to be true verhaal is. Ondertussen geloven wij er daadwerkelijk in dat het gewoon kan. Maar je merkt dat dat ook nog iets is wat we leveren. Dat het ook een beetje een to good to be true verhaal is. En dat het ook een beetje een to good to be true verhaal is. En dat het ook een beetje een to good to be true verhaal is. Dat is ook nog iets wat wel leeft bij sales gesprekken. Dan geven we vast een kleine cliffhanger. Het lijkt een to good to be true. Maar het kan echt. Oké. Ik heb het gevoel dat NoFlow zelf niet eens beseft. Op het gebied van WMS bijvoorbeeld. Hoe ver ze zijn. Want afgelopen\n",
            "\n",
            "========================================\n",
            "\n",
            "\n",
            "\n",
            "INFO:__main__:========================================\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Waarom gaan Moduchain en Novulo een partnership aan?\n",
            "Relevant Documents:\n",
            "1. De komende tijd de combinatie Novolo voor de logistiek. Dus als ik daar het taal naar de componenten zijn dat WMS componenten. Ja, in eerste instantie. Dus we hebben hier een inleiding voor. Ik denk wat belangrijk is waar wij voor staan. En waarom we zo'n goede match hebben met Novolo. Modulair supply chain. Wij staan voor modulairiteit. Dus gebruik wat je nodig hebt. En ook niet teveel, niet een overkeel. Maar je wil ook weer hebben wat je nodig hebt. En plug and play. Wat je ook wel veel ziet bij innovaties in de markt. Dat je heel veel tijd kwijt bent aan integratie ervan. Wij willen steeds meer naar plug and play. Dus makkelijker nieuwe functionaliteiten toevoegen. Daar sluit Novolo natuurlijk perfect op aan. Het moet innovatief zijn. Of innovaties kunnen faciliteren. En wat wij heel erg extra doen is menselijk aanpak. Ja, wat we in de afgelopen jaren wel vaak hebben gezien. Is dat als er een technische implementatie is. Waarbij het management, laat ik het even chargeren, gekozen\n",
            "========================================\n",
            "\n",
            "\n",
            "Question: Kun je uitleggen hoe het partnership implementaties en development beslaat?\n",
            "Relevant Documents:\n",
            "1. Of innovaties kunnen faciliteren. En wat wij heel erg extra doen is menselijk aanpak. Ja, wat we in de afgelopen jaren wel vaak hebben gezien. Is dat als er een technische implementatie is. Waarbij het management, laat ik het even chargeren, gekozen heeft voor een bepaald pakket. En dat wordt zeg maar op de werkvloer gegooid. Dan is de draagvlakvraag niet heel. En zijn de resultaten dus ook niet heel. En dus zijn wij in ons implementatie model gaat de mens en technologie samen. En is het heel belangrijk om de draagvlak juist goed te organiseren. Zodat je ook echt profiteert van hetgeen wat je wil gaan doen. En even kijken, zijn jullie een solution provider of een consultancy club? Beide. Dus we hebben een solution. Als ik het vertaal naar NoFlow doen we een implementatie trajecten. Maar we willen ook componenten gaan ontwikkelen. En dan voornamelijk op het WMS stuk. In de groep WMS functionaliteiten en TMS functionaliteiten en OMS functionaliteiten. Dus eigenlijk alles wat supply\n",
            "========================================\n",
            "\n",
            "\n",
            "Question: Wat voor innovaties zullen er in het warehouse komen?\n",
            "Relevant Documents:\n",
            "1. De komende tijd de combinatie Novolo voor de logistiek. Dus als ik daar het taal naar de componenten zijn dat WMS componenten. Ja, in eerste instantie. Dus we hebben hier een inleiding voor. Ik denk wat belangrijk is waar wij voor staan. En waarom we zo'n goede match hebben met Novolo. Modulair supply chain. Wij staan voor modulairiteit. Dus gebruik wat je nodig hebt. En ook niet teveel, niet een overkeel. Maar je wil ook weer hebben wat je nodig hebt. En plug and play. Wat je ook wel veel ziet bij innovaties in de markt. Dat je heel veel tijd kwijt bent aan integratie ervan. Wij willen steeds meer naar plug and play. Dus makkelijker nieuwe functionaliteiten toevoegen. Daar sluit Novolo natuurlijk perfect op aan. Het moet innovatief zijn. Of innovaties kunnen faciliteren. En wat wij heel erg extra doen is menselijk aanpak. Ja, wat we in de afgelopen jaren wel vaak hebben gezien. Is dat als er een technische implementatie is. Waarbij het management, laat ik het even chargeren, gekozen\n",
            "========================================\n",
            "\n",
            "\n",
            "Question: Wat is citizen development en wat kun je ermee bereiken vindt Moduchain?\n",
            "Relevant Documents:\n",
            "1. altijd al ons ondernemerschap naar voren. We hadden het al bezig met proposities rondom supply chain. Want dat is onze invalshoek. En die komt nu dan een paar jaar later via Modichain. Maar als consultant, het snijvlak tussen business en IT is echt hetgeen wat wij begrijpen. Dat ligt in onze expertise. En we hebben verschillende industrieën en organisaties gezien. Dus wat ik eerder zei, bij Philips in de healthcare tak gezeten. Bij Rituals als omnichannel businessanalyst gewerkt. Bij Amgen in de gezondheidszorg. Dus meer patiënt gerelateerde zorgpaden. Maar de rode draad blijft eigenlijk altijd hetzelfde. Dat is namelijk het begrijpen van de businessbehoeften. En begrijpen hoe IT daar een ondersteunende rol in kan vinden. En er dan ook voor zorgen dat dat gerealiseerd wordt. Oké. Even kijken, mijn achtergrond is combinatie van communicatie en technologie. Ik heb onder andere bij Chipsoft gewerkt. Dus in de medische sector als projectmanager. Maar ook een tijd lang in de media gewerkt.\n",
            "========================================\n",
            "\n",
            "\n",
            "Question: Waarom is application composition platform van Novulo te mooi om waar te zijn?\n",
            "Relevant Documents:\n",
            "1. nieuw. Ja precies. Frank heeft die term bij ons geïntroduceerd. Ja, dit is ook pas. Het is nog geen jaar dat Gartner er heel stevig mee komt. Ze hebben het bij model IT in gereild voor application composition. Om bedrijven aan het innoveren en te krijgen. En verbindbaar te maken. Ja. We hadden wel sterk het gevoel in het begin toen we hier mee in aanraking kwamen. Dat het een beetje zo'n to good to be true verhaal is. Ondertussen geloven wij er daadwerkelijk in dat het gewoon kan. Maar je merkt dat dat ook nog iets is wat we leveren. Dat het ook een beetje een to good to be true verhaal is. En dat het ook een beetje een to good to be true verhaal is. En dat het ook een beetje een to good to be true verhaal is. Dat is ook nog iets wat wel leeft bij sales gesprekken. Dan geven we vast een kleine cliffhanger. Het lijkt een to good to be true. Maar het kan echt. Oké. Ik heb het gevoel dat NoFlow zelf niet eens beseft. Op het gebied van WMS bijvoorbeeld. Hoe ver ze zijn. Want afgelopen\n",
            "========================================\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Search with more context"
      ],
      "metadata": {
        "id": "OcJEUr0jGah-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ask questions using context optimally\n",
        "def ask_questions_in_context(retriever, questions, context):\n",
        "  logger = setup_logging('ask_questions_in_context')\n",
        "  retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
        "\n",
        "  template = \"\"\"\n",
        "    Ik wil dat je als een assistent die onderzoekt acteert. Je geeft zo volledig mogelijk antwoord op mijn vragen.\n",
        "\n",
        "    Context: {context}\n",
        "    Question: {question}?\n",
        "    \"\"\"\n",
        "\n",
        "  prompt = PromptTemplate(\n",
        "        input_variables=[\"question\", \"context\"],\n",
        "        template=template,\n",
        "    )\n",
        "\n",
        "  llm = OpenAI(temperature=0)\n",
        "  compressor = LLMChainExtractor.from_llm(llm)\n",
        "  compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)\n",
        "\n",
        "  results = {}  # Initialize the dictionary here\n",
        "\n",
        "  for question in questions:\n",
        "    compressed_docs = compression_retriever.get_relevant_documents(question)\n",
        "    llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
        "    llm_chain_output = llm_chain.predict(question=question, context=compressed_docs)\n",
        "    results[question] = llm_chain_output\n",
        "\n",
        "  for question, answer in results.items():\n",
        "        logger.info(f'Question: {question}\\nAnswer: {answer}\\n')\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "9T1LI02eNl89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling function\n",
        "questions = [\n",
        "    \"Waarom gaan Moduchain en Novulo een partnership aan?\",\n",
        "    \"Kun je uitleggen hoe het partnership implementaties en development beslaat?\",\n",
        "    \"Wat voor innovaties zullen er in het warehouse komen?\",\n",
        "    \"Wat is citizen development en wat kun je ermee bereiken vindt Moduchain?\",\n",
        "    \"Waarom is application composition platform van Novulo te mooi om waar te zijn?\",\n",
        "]\n",
        "\n",
        "context = \"Moduchain gelooft in modulaire supply chains, waarbij de inzet van het Novulo application platform ervoor zorgt dat er gemakkelijk functionaliteiten zijn toe te voegen.\"  # replace with actual context\n",
        "answers = ask_questions_in_context(retriever, questions, context)"
      ],
      "metadata": {
        "id": "gwEOuBR4OCBq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c7a02ec-66ad-4685-f09e-5ca16a21330c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:backoff:Giving up send_request(...) after 4 tries (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.posthog.com', port=443): Read timed out. (read timeout=15))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    Ik wil dat je als een assistent die onderzoekt acteert. Je geeft zo volledig mogelijk antwoord op mijn vragen.\n",
            "\n",
            "    Context: [Document(page_content='\"Modulair supply chain. Wij staan voor modulairiteit. Dus gebruik wat je nodig hebt. En ook niet teveel, niet een overkeel. Maar je wil ook weer hebben wat je nodig hebt. En plug and play. Wat je ook wel veel ziet bij innovaties in de markt. Dat je heel veel tijd kwijt bent aan integratie ervan. Wij willen steeds meer naar plug and play. Dus makkelijker nieuwe functionaliteiten toevoegen. Daar sluit Novolo natuurlijk perfect op aan. Het moet innovatief zijn. Of innovaties kunnen faciliteren.\"', metadata={'source': '/content/drive/MyDrive/Data/q_a/moduchain/transcriptie-moduchain.txt'})]\n",
            "    Question: Waarom gaan Moduchain en Novulo een partnership aan??\n",
            "    \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off send_request(...) for 0.6s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.posthog.com', port=443): Read timed out. (read timeout=15))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    Ik wil dat je als een assistent die onderzoekt acteert. Je geeft zo volledig mogelijk antwoord op mijn vragen.\n",
            "\n",
            "    Context: []\n",
            "    Question: Kun je uitleggen hoe het partnership implementaties en development beslaat??\n",
            "    \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
            "INFO:backoff:Backing off send_request(...) for 0.4s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.posthog.com', port=443): Read timed out. (read timeout=15))\n",
            "INFO:backoff:Backing off send_request(...) for 1.1s (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.posthog.com', port=443): Read timed out. (read timeout=15))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:backoff:Giving up send_request(...) after 4 tries (requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.posthog.com', port=443): Read timed out. (read timeout=15))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    Ik wil dat je als een assistent die onderzoekt acteert. Je geeft zo volledig mogelijk antwoord op mijn vragen.\n",
            "\n",
            "    Context: [Document(page_content='\"Modulair supply chain. Wij staan voor modulairiteit. Dus gebruik wat je nodig hebt. En ook niet teveel, niet een overkeel. Maar je wil ook weer hebben wat je nodig hebt. En plug and play. Wat je ook wel veel ziet bij innovaties in de markt. Dat je heel veel tijd kwijt bent aan integratie ervan. Wij willen steeds meer naar plug and play. Dus makkelijker nieuwe functionaliteiten toevoegen. Daar sluit Novolo natuurlijk perfect op aan. Het moet innovatief zijn. Of innovaties kunnen faciliteren.\"', metadata={'source': '/content/drive/MyDrive/Data/q_a/moduchain/transcriptie-moduchain.txt'})]\n",
            "    Question: Wat voor innovaties zullen er in het warehouse komen??\n",
            "    \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    Ik wil dat je als een assistent die onderzoekt acteert. Je geeft zo volledig mogelijk antwoord op mijn vragen.\n",
            "\n",
            "    Context: []\n",
            "    Question: Wat is citizen development en wat kun je ermee bereiken vindt Moduchain??\n",
            "    \u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    Ik wil dat je als een assistent die onderzoekt acteert. Je geeft zo volledig mogelijk antwoord op mijn vragen.\n",
            "\n",
            "    Context: [Document(page_content='\"Het is nog geen jaar dat Gartner er heel stevig mee komt. Ze hebben het bij model IT in gereild voor application composition. Om bedrijven aan het innoveren en te krijgen. En verbindbaar te maken. Ja. We hadden wel sterk het gevoel in het begin toen we hier mee in aanraking kwamen. Dat het een beetje zo\\'n to good to be true verhaal is.\"', metadata={'source': '/content/drive/MyDrive/Data/q_a/moduchain/transcriptie-moduchain.txt'})]\n",
            "    Question: Waarom is application composition platform van Novulo te mooi om waar te zijn??\n",
            "    \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Question: Waarom gaan Moduchain en Novulo een partnership aan?\n",
            "Answer: \n",
            "Antwoord: Moduchain en Novolo gaan een partnership aan omdat Novolo perfect aansluit op de modulairiteit die Moduchain voorstaat. Novolo biedt innovatieve functionaliteiten die makkelijk toe te voegen zijn, waardoor Moduchain in staat is om snel nieuwe innovaties te implementeren.\n",
            "\n",
            "INFO:__main__:Question: Waarom gaan Moduchain en Novulo een partnership aan?\n",
            "Answer: \n",
            "Antwoord: Moduchain en Novolo gaan een partnership aan omdat Novolo perfect aansluit op de modulairiteit die Moduchain voorstaat. Novolo biedt innovatieve functionaliteiten die makkelijk toe te voegen zijn, waardoor Moduchain in staat is om snel nieuwe innovaties te implementeren.\n",
            "\n",
            "Question: Kun je uitleggen hoe het partnership implementaties en development beslaat?\n",
            "Answer: \n",
            "Answer: Ja, het partnership implementaties en development beslaat een aantal verschillende aspecten. Ten eerste zal het partnership de ontwikkeling van nieuwe producten en diensten bevorderen. Dit kan door het aanbieden van technische ondersteuning, het verstrekken van advies en het verstrekken van financiële middelen. Daarnaast zal het partnership ook de implementatie van bestaande producten en diensten bevorderen. Dit kan door het aanbieden van technische ondersteuning, het verstrekken van advies en het verstrekken van financiële middelen. Tenslotte zal het partnership ook de ontwikkeling van nieuwe technologieën bevorderen. Dit kan door het aanbieden van technische ondersteuning, het verstrekken van advies en het verstrekken van financiële middelen.\n",
            "\n",
            "INFO:__main__:Question: Kun je uitleggen hoe het partnership implementaties en development beslaat?\n",
            "Answer: \n",
            "Answer: Ja, het partnership implementaties en development beslaat een aantal verschillende aspecten. Ten eerste zal het partnership de ontwikkeling van nieuwe producten en diensten bevorderen. Dit kan door het aanbieden van technische ondersteuning, het verstrekken van advies en het verstrekken van financiële middelen. Daarnaast zal het partnership ook de implementatie van bestaande producten en diensten bevorderen. Dit kan door het aanbieden van technische ondersteuning, het verstrekken van advies en het verstrekken van financiële middelen. Tenslotte zal het partnership ook de ontwikkeling van nieuwe technologieën bevorderen. Dit kan door het aanbieden van technische ondersteuning, het verstrekken van advies en het verstrekken van financiële middelen.\n",
            "\n",
            "Question: Wat voor innovaties zullen er in het warehouse komen?\n",
            "Answer: \n",
            "Antwoord: Novolo biedt innovatieve oplossingen voor het warehouse, waaronder plug-and-play functionaliteiten die het mogelijk maken om nieuwe functionaliteiten eenvoudig toe te voegen. Deze innovaties kunnen het warehouse helpen om efficiënter te werken en meer flexibiliteit te bieden.\n",
            "\n",
            "INFO:__main__:Question: Wat voor innovaties zullen er in het warehouse komen?\n",
            "Answer: \n",
            "Antwoord: Novolo biedt innovatieve oplossingen voor het warehouse, waaronder plug-and-play functionaliteiten die het mogelijk maken om nieuwe functionaliteiten eenvoudig toe te voegen. Deze innovaties kunnen het warehouse helpen om efficiënter te werken en meer flexibiliteit te bieden.\n",
            "\n",
            "Question: Wat is citizen development en wat kun je ermee bereiken vindt Moduchain?\n",
            "Answer: \n",
            "Answer: Citizen development is een manier om software te ontwikkelen waarbij gebruikers zelf de controle hebben over hun eigen data en applicaties. Met citizen development kunnen gebruikers hun eigen applicaties bouwen, beheren en beveiligen. Moduchain biedt een platform waarmee gebruikers hun eigen applicaties kunnen bouwen, beheren en beveiligen. Het platform biedt ook een aantal tools waarmee gebruikers hun applicaties kunnen ontwikkelen, testen en implementeren. Met Moduchain kunnen gebruikers hun eigen applicaties bouwen, beheren en beveiligen, waardoor ze meer controle hebben over hun eigen data en applicaties.\n",
            "\n",
            "INFO:__main__:Question: Wat is citizen development en wat kun je ermee bereiken vindt Moduchain?\n",
            "Answer: \n",
            "Answer: Citizen development is een manier om software te ontwikkelen waarbij gebruikers zelf de controle hebben over hun eigen data en applicaties. Met citizen development kunnen gebruikers hun eigen applicaties bouwen, beheren en beveiligen. Moduchain biedt een platform waarmee gebruikers hun eigen applicaties kunnen bouwen, beheren en beveiligen. Het platform biedt ook een aantal tools waarmee gebruikers hun applicaties kunnen ontwikkelen, testen en implementeren. Met Moduchain kunnen gebruikers hun eigen applicaties bouwen, beheren en beveiligen, waardoor ze meer controle hebben over hun eigen data en applicaties.\n",
            "\n",
            "Question: Waarom is application composition platform van Novulo te mooi om waar te zijn?\n",
            "Answer: \n",
            "Antwoord: Application composition platform van Novulo lijkt te mooi om waar te zijn omdat het bedrijven in staat stelt om te innoveren en verbindbaar te maken. Gartner heeft het bij model IT in gereild voor application composition, wat suggereert dat het een veelbelovende oplossing is.\n",
            "\n",
            "INFO:__main__:Question: Waarom is application composition platform van Novulo te mooi om waar te zijn?\n",
            "Answer: \n",
            "Antwoord: Application composition platform van Novulo lijkt te mooi om waar te zijn omdat het bedrijven in staat stelt om te innoveren en verbindbaar te maken. Gartner heeft het bij model IT in gereild voor application composition, wat suggereert dat het een veelbelovende oplossing is.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LLM augmented search"
      ],
      "metadata": {
        "id": "62tQyGeaOk8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmenting search with LLM\n",
        "def ask_questions_augmented(retriever, openai_api_key, queries):\n",
        "  logger = setup_logging('ask_questions_augmented')\n",
        "  llm = ChatOpenAI(\n",
        "        openai_api_key=openai_api_key,\n",
        "        model_name='gpt-3.5-turbo',\n",
        "        temperature=0.0\n",
        "        )\n",
        "\n",
        "  qa = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1}),\n",
        "        verbose=True,\n",
        "        input_key=\"query\"\n",
        "        )\n",
        "\n",
        "  results = {}\n",
        "  for query in queries:\n",
        "        result = qa.run(query)\n",
        "        results[query] = result\n",
        "\n",
        "  for query, result in results.items():\n",
        "        logger.info(f'Query: {query}\\nAnswer: {result}\\n')\n",
        "        logger.info(\"=\" * 40)\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "dTHI_i-yOn8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling the function\n",
        "queries = [\n",
        "    \"Waarom gaan Moduchain en Novulo een partnership aan?\",\n",
        "    \"Kun je uitleggen hoe het partnership implementaties en development beslaat?\",\n",
        "    \"Wat voor innovaties zullen er in het warehouse komen?\",\n",
        "    \"Wat is citizen development en wat kun je ermee bereiken vindt Moduchain?\",\n",
        "    \"Waarom is application composition platform van Novulo te mooi om waar te zijn?\",\n",
        "    # add more questions here\n",
        "]\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai_api_key = openai_api_key\n",
        "\n",
        "# Call the function\n",
        "answers = ask_questions_augmented(retriever, openai_api_key, queries)\n",
        "\n",
        "# If you want to print the returned answers dictionary\n",
        "for query, answer in answers.items():\n",
        "    print(f\"Query: {query}\\nAnswer: {answer}\\n\" + \"=\" * 40)"
      ],
      "metadata": {
        "id": "GVnSFpjSPRjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53c68a7-c0d9-41bb-ef4c-a1e880bf292f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Query: Waarom gaan Moduchain en Novulo een partnership aan?\n",
            "Answer: Moduchain en Novulo gaan een partnership aan omdat Moduchain staat voor modulaire supply chain en plug-and-play-functionaliteiten, terwijl Novulo innovatieve oplossingen biedt die gemakkelijk kunnen worden geïntegreerd. Bovendien hecht Moduchain veel waarde aan een menselijke aanpak bij technische implementaties, wat ook goed past bij de werkwijze van Novulo. Door samen te werken kunnen ze hun krachten bundelen en hun klanten beter bedienen.\n",
            "\n",
            "INFO:__main__:Query: Waarom gaan Moduchain en Novulo een partnership aan?\n",
            "Answer: Moduchain en Novulo gaan een partnership aan omdat Moduchain staat voor modulaire supply chain en plug-and-play-functionaliteiten, terwijl Novulo innovatieve oplossingen biedt die gemakkelijk kunnen worden geïntegreerd. Bovendien hecht Moduchain veel waarde aan een menselijke aanpak bij technische implementaties, wat ook goed past bij de werkwijze van Novulo. Door samen te werken kunnen ze hun krachten bundelen en hun klanten beter bedienen.\n",
            "\n",
            "========================================\n",
            "INFO:__main__:========================================\n",
            "Query: Kun je uitleggen hoe het partnership implementaties en development beslaat?\n",
            "Answer: Ja, natuurlijk. Het partnership van deze organisatie omvat zowel implementaties als ontwikkeling. Ze bieden implementatietrajecten aan als een solution provider en willen ook componenten ontwikkelen, voornamelijk op het gebied van WMS, TMS en OMS functionaliteiten. Het is dus een combinatie van consultancy en ontwikkeling. Ze vinden het belangrijk om de menselijke aanpak te integreren in hun implementatiemodel, omdat ze hebben gezien dat technische implementaties zonder draagvlak niet succesvol zijn. Daarom organiseren ze de draagvlak goed om ervoor te zorgen dat de resultaten van de implementatie ook daadwerkelijk positief zijn.\n",
            "\n",
            "INFO:__main__:Query: Kun je uitleggen hoe het partnership implementaties en development beslaat?\n",
            "Answer: Ja, natuurlijk. Het partnership van deze organisatie omvat zowel implementaties als ontwikkeling. Ze bieden implementatietrajecten aan als een solution provider en willen ook componenten ontwikkelen, voornamelijk op het gebied van WMS, TMS en OMS functionaliteiten. Het is dus een combinatie van consultancy en ontwikkeling. Ze vinden het belangrijk om de menselijke aanpak te integreren in hun implementatiemodel, omdat ze hebben gezien dat technische implementaties zonder draagvlak niet succesvol zijn. Daarom organiseren ze de draagvlak goed om ervoor te zorgen dat de resultaten van de implementatie ook daadwerkelijk positief zijn.\n",
            "\n",
            "========================================\n",
            "INFO:__main__:========================================\n",
            "Query: Wat voor innovaties zullen er in het warehouse komen?\n",
            "Answer: Het gesprek gaat over de combinatie van Novolo voor de logistiek en hoe het bedrijf staat voor modulaire supply chain en plug-and-play. Er wordt niet specifiek gesproken over welke innovaties er in het warehouse zullen komen. Dus, ik kan geen antwoord geven op uw vraag.\n",
            "\n",
            "INFO:__main__:Query: Wat voor innovaties zullen er in het warehouse komen?\n",
            "Answer: Het gesprek gaat over de combinatie van Novolo voor de logistiek en hoe het bedrijf staat voor modulaire supply chain en plug-and-play. Er wordt niet specifiek gesproken over welke innovaties er in het warehouse zullen komen. Dus, ik kan geen antwoord geven op uw vraag.\n",
            "\n",
            "========================================\n",
            "INFO:__main__:========================================\n",
            "Query: Wat is citizen development en wat kun je ermee bereiken vindt Moduchain?\n",
            "Answer: Er is geen informatie in de gegeven context die specifiek ingaat op de visie van Moduchain over citizen development. Het is dus niet mogelijk om de vraag te beantwoorden met de gegeven informatie.\n",
            "\n",
            "INFO:__main__:Query: Wat is citizen development en wat kun je ermee bereiken vindt Moduchain?\n",
            "Answer: Er is geen informatie in de gegeven context die specifiek ingaat op de visie van Moduchain over citizen development. Het is dus niet mogelijk om de vraag te beantwoorden met de gegeven informatie.\n",
            "\n",
            "========================================\n",
            "INFO:__main__:========================================\n",
            "Query: Waarom is application composition platform van Novulo te mooi om waar te zijn?\n",
            "Answer: In het begin had het team het gevoel dat het een beetje te mooi was om waar te zijn, maar nu geloven ze er daadwerkelijk in dat het kan. Het lijkt nog steeds een beetje te mooi om waar te zijn voor sommige mensen tijdens salesgesprekken, maar het team is ervan overtuigd dat het echt kan. Er wordt niet specifiek vermeld waarom het te mooi lijkt om waar te zijn, maar het kan te maken hebben met de belofte van het platform om bedrijven te helpen innoveren en verbindbaar te maken.\n",
            "\n",
            "INFO:__main__:Query: Waarom is application composition platform van Novulo te mooi om waar te zijn?\n",
            "Answer: In het begin had het team het gevoel dat het een beetje te mooi was om waar te zijn, maar nu geloven ze er daadwerkelijk in dat het kan. Het lijkt nog steeds een beetje te mooi om waar te zijn voor sommige mensen tijdens salesgesprekken, maar het team is ervan overtuigd dat het echt kan. Er wordt niet specifiek vermeld waarom het te mooi lijkt om waar te zijn, maar het kan te maken hebben met de belofte van het platform om bedrijven te helpen innoveren en verbindbaar te maken.\n",
            "\n",
            "========================================\n",
            "INFO:__main__:========================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: Waarom gaan Moduchain en Novulo een partnership aan?\n",
            "Answer: Moduchain en Novulo gaan een partnership aan omdat Moduchain staat voor modulaire supply chain en plug-and-play-functionaliteiten, terwijl Novulo innovatieve oplossingen biedt die gemakkelijk kunnen worden geïntegreerd. Bovendien hecht Moduchain veel waarde aan een menselijke aanpak bij technische implementaties, wat ook goed past bij de werkwijze van Novulo. Door samen te werken kunnen ze hun krachten bundelen en hun klanten beter bedienen.\n",
            "========================================\n",
            "Query: Kun je uitleggen hoe het partnership implementaties en development beslaat?\n",
            "Answer: Ja, natuurlijk. Het partnership van deze organisatie omvat zowel implementaties als ontwikkeling. Ze bieden implementatietrajecten aan als een solution provider en willen ook componenten ontwikkelen, voornamelijk op het gebied van WMS, TMS en OMS functionaliteiten. Het is dus een combinatie van consultancy en ontwikkeling. Ze vinden het belangrijk om de menselijke aanpak te integreren in hun implementatiemodel, omdat ze hebben gezien dat technische implementaties zonder draagvlak niet succesvol zijn. Daarom organiseren ze de draagvlak goed om ervoor te zorgen dat de resultaten van de implementatie ook daadwerkelijk positief zijn.\n",
            "========================================\n",
            "Query: Wat voor innovaties zullen er in het warehouse komen?\n",
            "Answer: Het gesprek gaat over de combinatie van Novolo voor de logistiek en hoe het bedrijf staat voor modulaire supply chain en plug-and-play. Er wordt niet specifiek gesproken over welke innovaties er in het warehouse zullen komen. Dus, ik kan geen antwoord geven op uw vraag.\n",
            "========================================\n",
            "Query: Wat is citizen development en wat kun je ermee bereiken vindt Moduchain?\n",
            "Answer: Er is geen informatie in de gegeven context die specifiek ingaat op de visie van Moduchain over citizen development. Het is dus niet mogelijk om de vraag te beantwoorden met de gegeven informatie.\n",
            "========================================\n",
            "Query: Waarom is application composition platform van Novulo te mooi om waar te zijn?\n",
            "Answer: In het begin had het team het gevoel dat het een beetje te mooi was om waar te zijn, maar nu geloven ze er daadwerkelijk in dat het kan. Het lijkt nog steeds een beetje te mooi om waar te zijn voor sommige mensen tijdens salesgesprekken, maar het team is ervan overtuigd dat het echt kan. Er wordt niet specifiek vermeld waarom het te mooi lijkt om waar te zijn, maar het kan te maken hebben met de belofte van het platform om bedrijven te helpen innoveren en verbindbaar te maken.\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LLM augmented search with sources"
      ],
      "metadata": {
        "id": "G3S0epw-Y0DQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_questions_augmented_with_sources(retriever, vectordb, questions):\n",
        "    logger = setup_logging('ask_questions_augmented_with_sources')\n",
        "    chain = RetrievalQAWithSourcesChain.from_chain_type(OpenAI(temperature=0), chain_type=\"stuff\", retriever=vector_store.as_retriever())\n",
        "    qa_chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
        "    qa = RetrievalQAWithSourcesChain(combine_documents_chain=qa_chain, retriever=vector_store.as_retriever())\n",
        "\n",
        "    results = {}\n",
        "    for question in questions:\n",
        "        result = chain({\"question\": question}, {\"input_documents\": vectordb})\n",
        "        results[question] = result\n",
        "\n",
        "    for question, answer in results.items():\n",
        "        logger.info(f'Question: {question}\\nAnswer: {answer}\\n')\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "dWFspgOyY3Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling the function\n",
        "questions = [\n",
        "\"Waarom gaan Moduchain en Novulo een partnership aan?\",\n",
        "    \"Kun je uitleggen hoe het partnership implementaties en development beslaat?\",\n",
        "    \"Wat voor innovaties zullen er in het warehouse komen?\",\n",
        "    \"Wat is citizen development en wat kun je ermee bereiken vindt Moduchain?\",\n",
        "    \"Waarom is application composition platform van Novulo te mooi om waar te zijn?\",\n",
        "    # add more questions here\n",
        "]\n",
        "\n",
        "# Call the function\n",
        "answers = ask_questions_augmented_with_sources(retriever, vector_store, questions)"
      ],
      "metadata": {
        "id": "pKmsWS0hY5xV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7bba29-fe58-4724-e0ad-983ad5c45145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Question: Waarom gaan Moduchain en Novulo een partnership aan?\n",
            "Answer: {'answer': ' Moduchain en Novulo gaan een partnership aan om innovatieve oplossingen te implementeren bij bedrijven met supply chain vragenstukken, zoals logistieke dienstverleners, productiebedrijven en maakindustrie.\\n', 'sources': '/content/drive/MyDrive/Data/q_a/moduchain/transcriptie-moduchain.txt'}\n",
            "\n",
            "INFO:__main__:Question: Waarom gaan Moduchain en Novulo een partnership aan?\n",
            "Answer: {'answer': ' Moduchain en Novulo gaan een partnership aan om innovatieve oplossingen te implementeren bij bedrijven met supply chain vragenstukken, zoals logistieke dienstverleners, productiebedrijven en maakindustrie.\\n', 'sources': '/content/drive/MyDrive/Data/q_a/moduchain/transcriptie-moduchain.txt'}\n",
            "\n",
            "Question: Kun je uitleggen hoe het partnership implementaties en development beslaat?\n",
            "Answer: {'answer': ' Moduchain biedt een partnership aan waarbij zij het NoFlow platform implementeren en componenten ontwikkelen op het WMS, TMS en OMS gebied. Daarnaast bieden zij ook een menselijke aanpak om draagvlak te creëren en bieden zij ook de mogelijkheid voor citizen development.\\n', 'sources': '/content/drive/MyDrive/Data/q_a/moduchain/transcriptie-moduchain.txt'}\n",
            "\n",
            "INFO:__main__:Question: Kun je uitleggen hoe het partnership implementaties en development beslaat?\n",
            "Answer: {'answer': ' Moduchain biedt een partnership aan waarbij zij het NoFlow platform implementeren en componenten ontwikkelen op het WMS, TMS en OMS gebied. Daarnaast bieden zij ook een menselijke aanpak om draagvlak te creëren en bieden zij ook de mogelijkheid voor citizen development.\\n', 'sources': '/content/drive/MyDrive/Data/q_a/moduchain/transcriptie-moduchain.txt'}\n",
            "\n",
            "Question: Wat voor innovaties zullen er in het warehouse komen?\n",
            "Answer: {'answer': ' Moduchain staat voor innovatieve oplossingen, digitale innovaties die geïmplementeerd worden bij bedrijven met supply chain vragenstukken. Deze oplossingen zijn modulair, plug and play en hebben een menselijke aanpak.\\n', 'sources': '/content/drive/MyDrive/Data/q_a/moduchain/transcriptie-moduchain.txt'}\n",
            "\n",
            "INFO:__main__:Question: Wat voor innovaties zullen er in het warehouse komen?\n",
            "Answer: {'answer': ' Moduchain staat voor innovatieve oplossingen, digitale innovaties die geïmplementeerd worden bij bedrijven met supply chain vragenstukken. Deze oplossingen zijn modulair, plug and play en hebben een menselijke aanpak.\\n', 'sources': '/content/drive/MyDrive/Data/q_a/moduchain/transcriptie-moduchain.txt'}\n",
            "\n",
            "Question: Wat is citizen development en wat kun je ermee bereiken vindt Moduchain?\n",
            "Answer: {'answer': ' Moduchain beschouwt citizen development als een manier om innovatieve oplossingen te creëren voor bedrijven met supply chain vrijheden.\\n', 'sources': '/content/drive/MyDrive/Data/q_a/moduchain/transcriptie-moduchain.txt'}\n",
            "\n",
            "INFO:__main__:Question: Wat is citizen development en wat kun je ermee bereiken vindt Moduchain?\n",
            "Answer: {'answer': ' Moduchain beschouwt citizen development als een manier om innovatieve oplossingen te creëren voor bedrijven met supply chain vrijheden.\\n', 'sources': '/content/drive/MyDrive/Data/q_a/moduchain/transcriptie-moduchain.txt'}\n",
            "\n",
            "Question: Waarom is application composition platform van Novulo te mooi om waar te zijn?\n",
            "Answer: {'answer': \" Novulo's application composition platform biedt bedrijven de mogelijkheid om innovatieve oplossingen te implementeren met plug and play functionaliteiten en een menselijke aanpak.\\n\", 'sources': '/content/drive/MyDrive/Data/q_a/moduchain/transcriptie-moduchain.txt'}\n",
            "\n",
            "INFO:__main__:Question: Waarom is application composition platform van Novulo te mooi om waar te zijn?\n",
            "Answer: {'answer': \" Novulo's application composition platform biedt bedrijven de mogelijkheid om innovatieve oplossingen te implementeren met plug and play functionaliteiten en een menselijke aanpak.\\n\", 'sources': '/content/drive/MyDrive/Data/q_a/moduchain/transcriptie-moduchain.txt'}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}